{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vFwh8_BfgYvA",
   "metadata": {
    "id": "vFwh8_BfgYvA"
   },
   "source": [
    "# X-Ray Classification Training Notebook\n",
    "\n",
    "This notebook provides a complete pipeline for training the X-Ray classification model on Google Colab.\n",
    "\n",
    "**Prerequisites:**\n",
    "1.  Upload your cleaned dataset (as a zip file) to your Google Drive.\n",
    "2.  Mount your Google Drive in this notebook.\n",
    "3.  Update the `DATASET_ZIP_PATH` variable to point to your zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CKxjtaMKgYvE",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 37809,
     "status": "ok",
     "timestamp": 1763888794259,
     "user": {
      "displayName": "Kai Liang Ang (Kai)",
      "userId": "17787199631730325853"
     },
     "user_tz": -480
    },
    "id": "CKxjtaMKgYvE",
    "outputId": "8b022f45-f3c0-4b24-ac6d-1c7d69053206"
   },
   "outputs": [],
   "source": [
    "# @title 1. Setup & Dependencies\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install required libraries\n",
    "!pip install timm albumentations torchmetrics tensorboard pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "xO80w-fFgYvG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21378,
     "status": "ok",
     "timestamp": 1763888815646,
     "user": {
      "displayName": "Kai Liang Ang (Kai)",
      "userId": "17787199631730325853"
     },
     "user_tz": -480
    },
    "id": "xO80w-fFgYvG",
    "outputId": "a889d272-7eba-4f8a-f789-d9b42864027c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset from /content/drive/MyDrive/data.zip to /content/data...\n",
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# @title 2. Dataset Extraction\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# UPDATE THIS PATH to where your zip file is located on Google Drive\n",
    "DATASET_ZIP_PATH = '/content/drive/MyDrive/data.zip'\n",
    "EXTRACT_PATH = '/content/data'\n",
    "# ---------------------\n",
    "\n",
    "if not os.path.exists(EXTRACT_PATH):\n",
    "    print(f\"Extracting dataset from {DATASET_ZIP_PATH} to {EXTRACT_PATH}...\")\n",
    "    with zipfile.ZipFile(DATASET_ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_PATH)\n",
    "    print(\"Extraction complete.\")\n",
    "else:\n",
    "    print(f\"Dataset already exists at {EXTRACT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5XH1sSE8gYvG",
   "metadata": {
    "executionInfo": {
     "elapsed": 8769,
     "status": "ok",
     "timestamp": 1763888824387,
     "user": {
      "displayName": "Kai Liang Ang (Kai)",
      "userId": "17787199631730325853"
     },
     "user_tz": -480
    },
    "id": "5XH1sSE8gYvG"
   },
   "outputs": [],
   "source": [
    "# @title 3. Configuration\n",
    "import torch\n",
    "\n",
    "# Configuration dictionary\n",
    "CONFIG = {\n",
    "    \"paths\": {\n",
    "        \"data_root\": \"/content/data\",\n",
    "        \"models_dir\": \"/content/drive/MyDrive/CNN/models\",\n",
    "        \"logs_dir\": \"/content/drive/MyDrive/CNN/logs\"\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"splits\": [\"train\", \"val\", \"test\"],\n",
    "        \"classes\": [\"normal\", \"pneumonia\", \"tuberculosis\"],\n",
    "        \"image_exts\": [\".png\", \".jpg\", \".jpeg\"],\n",
    "        \"target_image_size\": [512, 512]\n",
    "    },\n",
    "    \"data_module\": {\n",
    "        \"batch_size\": 16,\n",
    "        \"num_workers\": 2,  # Colab usually has 2 CPUs\n",
    "        \"pin_memory\": True,\n",
    "        \"normalization_mean\": [0.485, 0.456, 0.406],\n",
    "        \"normalization_std\": [0.229, 0.224, 0.225],\n",
    "        \"use_weighted_sampler\": False\n",
    "    },\n",
    "    \"augmentation\": {\n",
    "        \"random_resized_crop\": {\n",
    "            \"scale\": [0.70, 1.0],\n",
    "            \"ratio\": [0.95, 1.05]\n",
    "        },\n",
    "        \"horizontal_flip\": False,\n",
    "        \"rotation_degrees\": 12,\n",
    "        \"color_jitter\": [0.1, 0.1, 0.1, 0.05],\n",
    "        \"color_jitter_prob\": 0.7\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"model_name\": \"tf_efficientnetv2_s\",\n",
    "        \"pretrained\": True,\n",
    "        \"batch_size\": 16,\n",
    "        \"epochs\": 30,\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"optimizer\": \"adamw\",\n",
    "        \"scheduler\": \"reduce_on_plateau\",\n",
    "        \"patience\": 3,\n",
    "        \"factor\": 0.5,\n",
    "        \"min_lr\": 1e-6,\n",
    "        \"label_smoothing\": 0.05,\n",
    "        \"use_class_weights\": True,\n",
    "        \"class_weights\": [0.9385, 1.4584, 0.8007]\n",
    "    },\n",
    "    \"evaluation\": {\n",
    "        \"metrics\": [\"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
    "        \"confusion_matrix\": True,\n",
    "        \"roc_auc\": True,\n",
    "        \"primary_metric\": \"accuracy\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "import os\n",
    "os.makedirs(CONFIG[\"paths\"][\"models_dir\"], exist_ok=True)\n",
    "os.makedirs(CONFIG[\"paths\"][\"logs_dir\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "NJVGDkxogYvH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1763888824425,
     "user": {
      "displayName": "Kai Liang Ang (Kai)",
      "userId": "17787199631730325853"
     },
     "user_tz": -480
    },
    "id": "NJVGDkxogYvH",
    "outputId": "ca0dd9eb-7433-4a5a-a797-5a47e5018886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# @title 4. Utilities & Imports\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional, Sequence, Tuple, List, Callable\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "\n",
    "def seed_everything(seed: int) -> None:\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def prepare_device(force_cpu: bool = False) -> torch.device:\n",
    "    \"\"\"Select the device for training.\"\"\"\n",
    "    if force_cpu or not torch.cuda.is_available():\n",
    "        return torch.device(\"cpu\")\n",
    "    return torch.device(\"cuda\")\n",
    "\n",
    "seed_everything(42)\n",
    "DEVICE = prepare_device()\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lBB6qp4igYvH",
   "metadata": {
    "executionInfo": {
     "elapsed": 21288,
     "status": "ok",
     "timestamp": 1763888845725,
     "user": {
      "displayName": "Kai Liang Ang (Kai)",
      "userId": "17787199631730325853"
     },
     "user_tz": -480
    },
    "id": "lBB6qp4igYvH"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "@dataclass\n",
    "class TransformConfig:\n",
    "    image_size: Tuple[int, int]\n",
    "    normalization_mean: Tuple[float, float, float]\n",
    "    normalization_std: Tuple[float, float, float]\n",
    "    augmentation_cfg: Dict\n",
    "\n",
    "class TransformFactory:\n",
    "    def __init__(self, config: TransformConfig) -> None:\n",
    "        self.config = config\n",
    "\n",
    "    def build_train_transforms(self) -> A.Compose:\n",
    "        augment_cfg = self.config.augmentation_cfg or {}\n",
    "        image_size = self.config.image_size\n",
    "        transforms = []\n",
    "\n",
    "        if augment_cfg.get(\"random_resized_crop\"):\n",
    "            params = augment_cfg[\"random_resized_crop\"]\n",
    "            transforms.append(\n",
    "                A.RandomResizedCrop(\n",
    "                    size=image_size, # Changed to pass size as a tuple\n",
    "                    scale=tuple(params.get(\"scale\", (0.9, 1.0))),\n",
    "                    ratio=tuple(params.get(\"ratio\", (0.9, 1.1))),\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            transforms.append(A.Resize(height=image_size[0], width=image_size[1]))\n",
    "\n",
    "        if augment_cfg.get(\"horizontal_flip\"):\n",
    "            transforms.append(A.HorizontalFlip(p=0.5))\n",
    "\n",
    "        if augment_cfg.get(\"rotation_degrees\"):\n",
    "            transforms.append(A.Rotate(limit=augment_cfg[\"rotation_degrees\"], p=0.5))\n",
    "\n",
    "        if augment_cfg.get(\"color_jitter\"):\n",
    "            brightness, contrast, saturation, hue = augment_cfg[\"color_jitter\"]\n",
    "            transforms.append(\n",
    "                A.ColorJitter(\n",
    "                    brightness=brightness, contrast=contrast, saturation=saturation, hue=hue,\n",
    "                    p=augment_cfg.get(\"color_jitter_prob\", 0.8),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        transforms.extend(self._common_transforms())\n",
    "        return A.Compose(transforms)\n",
    "\n",
    "    def build_eval_transforms(self) -> A.Compose:\n",
    "        image_size = self.config.image_size\n",
    "        transforms = [A.Resize(height=image_size[0], width=image_size[1])]\n",
    "        transforms.extend(self._common_transforms())\n",
    "        return A.Compose(transforms)\n",
    "\n",
    "    def _common_transforms(self):\n",
    "        return [\n",
    "            A.Normalize(\n",
    "                mean=self.config.normalization_mean,\n",
    "                std=self.config.normalization_std,\n",
    "                max_pixel_value=255.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "\n",
    "class AlbumentationsDataset(Dataset):\n",
    "    def __init__(self, dataset: ImageFolder, transform: A.Compose) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        path, label = self.dataset.samples[index]\n",
    "        with Image.open(path) as img:\n",
    "            image = img.convert(\"RGB\")\n",
    "        image_np = np.asarray(image)\n",
    "        transformed = self.transform(image=image_np)\n",
    "        return transformed[\"image\"], label\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "@dataclass\n",
    "class DataModuleConfig:\n",
    "    data_root: Path\n",
    "    classes: Sequence[str]\n",
    "    batch_size: int\n",
    "    num_workers: int\n",
    "    pin_memory: bool\n",
    "    image_size: Tuple[int, int]\n",
    "    normalization_mean: Tuple[float, float, float]\n",
    "    normalization_std: Tuple[float, float, float]\n",
    "    augmentation_cfg: Optional[Dict]\n",
    "    allowed_exts: Sequence[str]\n",
    "    use_weighted_sampler: bool = False\n",
    "\n",
    "class DataModule:\n",
    "    def __init__(self, config: DataModuleConfig) -> None:\n",
    "        self.config = config\n",
    "        transform_cfg = TransformConfig(\n",
    "            image_size=config.image_size,\n",
    "            normalization_mean=config.normalization_mean,\n",
    "            normalization_std=config.normalization_std,\n",
    "            augmentation_cfg=config.augmentation_cfg or {},\n",
    "        )\n",
    "        self.transform_factory = TransformFactory(transform_cfg)\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.class_to_idx = {}\n",
    "\n",
    "    def setup(self) -> None:\n",
    "        splits = {\n",
    "            \"train\": self.transform_factory.build_train_transforms,\n",
    "            \"val\": self.transform_factory.build_eval_transforms,\n",
    "            \"test\": self.transform_factory.build_eval_transforms,\n",
    "        }\n",
    "\n",
    "        for split, transform_builder in splits.items():\n",
    "            split_dir = self.config.data_root / split\n",
    "            if not split_dir.is_dir():\n",
    "                continue\n",
    "\n",
    "            base_dataset = ImageFolder(split_dir)\n",
    "            base_dataset = self._filter_by_extension(base_dataset)\n",
    "            base_dataset = self._align_class_indices(base_dataset, split)\n",
    "\n",
    "            transform = transform_builder()\n",
    "            alb_dataset = AlbumentationsDataset(base_dataset, transform)\n",
    "\n",
    "            if split == \"train\":\n",
    "                self.train_dataset = alb_dataset\n",
    "            elif split == \"val\":\n",
    "                self.val_dataset = alb_dataset\n",
    "            else:\n",
    "                self.test_dataset = alb_dataset\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        sampler = None\n",
    "        if self.config.use_weighted_sampler:\n",
    "            targets = [label for _, label in self.train_dataset.dataset.samples]\n",
    "            class_counts = Counter(targets)\n",
    "            num_classes = len(class_counts)\n",
    "            total = len(targets)\n",
    "            class_weights = {cls: total / (num_classes * count) for cls, count in class_counts.items()}\n",
    "            sample_weights = [class_weights[label] for label in targets]\n",
    "            sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=sampler is None,\n",
    "            sampler=sampler,\n",
    "            num_workers=self.config.num_workers,\n",
    "            pin_memory=self.config.pin_memory,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.config.num_workers,\n",
    "            pin_memory=self.config.pin_memory,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.config.num_workers,\n",
    "            pin_memory=self.config.pin_memory,\n",
    "        )\n",
    "\n",
    "    def _filter_by_extension(self, dataset: ImageFolder) -> ImageFolder:\n",
    "        allowed = {ext.lower() for ext in self.config.allowed_exts}\n",
    "        filtered_samples = [(p, l) for p, l in dataset.samples if Path(p).suffix.lower() in allowed]\n",
    "        dataset.samples = filtered_samples\n",
    "        dataset.imgs = filtered_samples\n",
    "        dataset.targets = [l for _, l in filtered_samples]\n",
    "        return dataset\n",
    "\n",
    "    def _align_class_indices(self, dataset: ImageFolder, split: str) -> ImageFolder:\n",
    "        if not self.class_to_idx:\n",
    "            self.class_to_idx = dataset.class_to_idx.copy()\n",
    "            return dataset\n",
    "\n",
    "        remapped_samples = []\n",
    "        for path, _ in dataset.samples:\n",
    "            class_name = Path(path).parent.name\n",
    "            if class_name in self.class_to_idx:\n",
    "                remapped_samples.append((path, self.class_to_idx[class_name]))\n",
    "\n",
    "        dataset.samples = remapped_samples\n",
    "        dataset.imgs = remapped_samples\n",
    "        dataset.targets = [l for _, l in remapped_samples]\n",
    "        dataset.class_to_idx = self.class_to_idx\n",
    "        dataset.classes = list(self.class_to_idx.keys())\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6LwpKDF3gYvI",
   "metadata": {
    "executionInfo": {
     "elapsed": 8387,
     "status": "ok",
     "timestamp": 1763888854113,
     "user": {
      "displayName": "Kai Liang Ang (Kai)",
      "userId": "17787199631730325853"
     },
     "user_tz": -480
    },
    "id": "6LwpKDF3gYvI"
   },
   "outputs": [],
   "source": [
    "# @title 6. Model Building\n",
    "import timm\n",
    "\n",
    "def build_model(model_cfg: Dict[str, Any], num_classes: int) -> torch.nn.Module:\n",
    "    model_name = model_cfg[\"model_name\"]\n",
    "    pretrained = bool(model_cfg.get(\"pretrained\", True))\n",
    "\n",
    "    print(f\"Building model: {model_name} (pretrained={pretrained})\")\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=pretrained,\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "htMUjMC9gYvJ",
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 6169,
     "status": "ok",
     "timestamp": 1763888860305,
     "user": {
      "displayName": "Kai Liang Ang (Kai)",
      "userId": "17787199631730325853"
     },
     "user_tz": -480
    },
    "id": "htMUjMC9gYvJ"
   },
   "outputs": [],
   "source": [
    "# @title 7. Training Components (Loss, Metrics, Optimizer)\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassAUROC, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "\n",
    "def build_loss(training_cfg: Dict[str, Any]) -> nn.Module:\n",
    "    label_smoothing = float(training_cfg.get(\"label_smoothing\", 0.0))\n",
    "    weight_tensor = None\n",
    "    if training_cfg.get(\"use_class_weights\"):\n",
    "        custom_weights = training_cfg.get(\"class_weights\")\n",
    "        if custom_weights:\n",
    "            weight_tensor = torch.tensor(custom_weights, dtype=torch.float32)\n",
    "    return nn.CrossEntropyLoss(weight=weight_tensor, label_smoothing=label_smoothing)\n",
    "\n",
    "def build_metrics(evaluation_cfg: Dict[str, Any], num_classes: int, device: torch.device) -> MetricCollection:\n",
    "    metric_names = evaluation_cfg.get(\"metrics\", [])\n",
    "    instances = {}\n",
    "    supported = {\n",
    "        \"accuracy\": MulticlassAccuracy,\n",
    "        \"precision\": MulticlassPrecision,\n",
    "        \"recall\": MulticlassRecall,\n",
    "        \"f1\": MulticlassF1Score,\n",
    "    }\n",
    "    for name in metric_names:\n",
    "        key = name.lower()\n",
    "        if key in supported:\n",
    "            instances[key] = supported[key](num_classes=num_classes, average=\"macro\")\n",
    "\n",
    "    if evaluation_cfg.get(\"roc_auc\", False):\n",
    "        instances[\"roc_auc\"] = MulticlassAUROC(num_classes=num_classes)\n",
    "\n",
    "    if not instances:\n",
    "        instances[\"accuracy\"] = MulticlassAccuracy(num_classes=num_classes)\n",
    "\n",
    "    return MetricCollection(instances).to(device)\n",
    "\n",
    "def build_optimizer(model: torch.nn.Module, training_cfg: Dict[str, Any]) -> torch.optim.Optimizer:\n",
    "    name = training_cfg.get(\"optimizer\", \"adam\").lower()\n",
    "    lr = float(training_cfg.get(\"learning_rate\", 1e-3))\n",
    "    weight_decay = float(training_cfg.get(\"weight_decay\", 0.0))\n",
    "    params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "\n",
    "    if name == \"adamw\":\n",
    "        return torch.optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
    "    return torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def build_scheduler(optimizer: torch.optim.Optimizer, training_cfg: Dict[str, Any], epochs: int):\n",
    "    name = training_cfg.get(\"scheduler\", \"none\").lower()\n",
    "    if name == \"reduce_on_plateau\":\n",
    "        return torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            patience=int(training_cfg.get(\"patience\", 3)),\n",
    "            factor=float(training_cfg.get(\"factor\", 0.1))\n",
    "        )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "EFMednpCgYvJ",
   "metadata": {
    "executionInfo": {
     "elapsed": 8642,
     "status": "ok",
     "timestamp": 1763888868973,
     "user": {
      "displayName": "Kai Liang Ang (Kai)",
      "userId": "17787199631730325853"
     },
     "user_tz": -480
    },
    "id": "EFMednpCgYvJ"
   },
   "outputs": [],
   "source": [
    "# @title 8. Trainer Class\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, device, loss_fn, optimizer, metric_collection, scheduler=None, epochs=25, checkpoint_dir=None, writer=None):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.metric_template = metric_collection\n",
    "        self.epochs = epochs\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.writer = writer\n",
    "        self.best_metric = float(\"-inf\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def fit(self, train_loader, val_loader=None):\n",
    "        history = {}\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            print(f\"\\nEpoch {epoch}/{self.epochs}\")\n",
    "            train_loss, train_metrics = self._run_epoch(train_loader, train=True)\n",
    "\n",
    "            val_loss, val_metrics = None, {}\n",
    "            if val_loader:\n",
    "                val_loss, val_metrics = self._run_epoch(val_loader, train=False)\n",
    "\n",
    "            # Logging\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"Train Acc: {train_metrics.get('train_accuracy', 0):.4f} | Val Acc: {val_metrics.get('val_accuracy', 0):.4f}\")\n",
    "\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "                self.writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "                self.writer.add_scalar(\"Accuracy/train\", train_metrics.get('train_accuracy', 0), epoch)\n",
    "                self.writer.add_scalar(\"Accuracy/val\", val_metrics.get('val_accuracy', 0), epoch)\n",
    "\n",
    "            # Save Best Model\n",
    "            if val_metrics.get('val_accuracy', 0) > self.best_metric:\n",
    "                self.best_metric = val_metrics['val_accuracy']\n",
    "                self._save_checkpoint(epoch, is_best=True)\n",
    "\n",
    "            # Scheduler Step\n",
    "            if self.scheduler:\n",
    "                if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    self.scheduler.step(val_loss)\n",
    "                else:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "    def _run_epoch(self, loader, train):\n",
    "        mode = \"train\" if train else \"val\"\n",
    "        self.model.train() if train else self.model.eval()\n",
    "\n",
    "        metric_collection = self.metric_template.clone(prefix=f\"{mode}_\")\n",
    "        metric_collection.reset()\n",
    "        total_loss = 0.0\n",
    "        total_items = 0\n",
    "\n",
    "        for images, targets in tqdm(loader, desc=mode, leave=False):\n",
    "            images, targets = images.to(self.device), targets.to(self.device)\n",
    "\n",
    "            with torch.set_grad_enabled(train):\n",
    "                logits = self.model(images)\n",
    "                loss = self.loss_fn(logits, targets)\n",
    "\n",
    "            if train:\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            total_items += images.size(0)\n",
    "            probs = torch.softmax(logits.detach(), dim=1)\n",
    "            metric_collection.update(probs, targets)\n",
    "\n",
    "        avg_loss = total_loss / max(total_items, 1)\n",
    "        metrics = metric_collection.compute()\n",
    "        metrics_dict = {k: v.item() for k, v in metrics.items()}\n",
    "        return avg_loss, metrics_dict\n",
    "\n",
    "    def _save_checkpoint(self, epoch, is_best=False):\n",
    "        if not self.checkpoint_dir: return\n",
    "        state = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": self.model.state_dict(),\n",
    "            \"optimizer_state\": self.optimizer.state_dict(),\n",
    "            \"config\": CONFIG\n",
    "        }\n",
    "        path = Path(self.checkpoint_dir) / f\"checkpoint_epoch_{epoch}.pth\"\n",
    "        torch.save(state, path)\n",
    "        if is_best:\n",
    "            torch.save(state, Path(self.checkpoint_dir) / \"best_model.pth\")\n",
    "            print(f\"Saved new best model to {Path(self.checkpoint_dir) / 'best_model.pth'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MKznqm-8gYvK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579,
     "referenced_widgets": [
      "8f11dffc8d2b4b8e9fe06a047eac1c2b",
      "9bb94f35443c4b47ab1196a71a3842d7",
      "f48d2ef3f8f143d48e149a289adc77b1",
      "c03bf6dcc5a04fea8fb069011a6404aa",
      "2f30910635914907b7b1064da803aca9",
      "2b166c86ef064bfcb408b895de1a3a14",
      "498a9ef0681f41f1a83d995a5eae9915",
      "8ff0c74af1454fd4bbbbd8cf8b0c1202",
      "5fa333c0b00746d8acf4ece60ac93ffa",
      "314f78d6193d4396a277bd603346f333",
      "29950943cb8e471d93be9c748e7b55af"
     ]
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8361,
     "status": "error",
     "timestamp": 1763888887083,
     "user": {
      "displayName": "Kai Liang Ang (Kai)",
      "userId": "17787199631730325853"
     },
     "user_tz": -480
    },
    "id": "MKznqm-8gYvK",
    "outputId": "4807f0ab-f19e-47d1-eef9-e1625917a279"
   },
   "outputs": [],
   "source": [
    "# @title 9. Run Training\n",
    "\n",
    "# Initialize Data Module\n",
    "dm_config = DataModuleConfig(\n",
    "    data_root=Path(CONFIG[\"paths\"][\"data_root\"]),\n",
    "    classes=tuple(CONFIG[\"dataset\"][\"classes\"]),\n",
    "    batch_size=CONFIG[\"training\"][\"batch_size\"],\n",
    "    num_workers=CONFIG[\"data_module\"][\"num_workers\"],\n",
    "    pin_memory=CONFIG[\"data_module\"][\"pin_memory\"],\n",
    "    image_size=tuple(CONFIG[\"dataset\"][\"target_image_size\"]),\n",
    "    normalization_mean=tuple(CONFIG[\"data_module\"][\"normalization_mean\"]),\n",
    "    normalization_std=tuple(CONFIG[\"data_module\"][\"normalization_std\"]),\n",
    "    augmentation_cfg=CONFIG[\"augmentation\"],\n",
    "    allowed_exts=tuple(CONFIG[\"dataset\"][\"image_exts\"]),\n",
    "    use_weighted_sampler=CONFIG[\"data_module\"][\"use_weighted_sampler\"]\n",
    ")\n",
    "\n",
    "data_module = DataModule(dm_config)\n",
    "data_module.setup()\n",
    "\n",
    "train_loader = data_module.train_dataloader()\n",
    "val_loader = data_module.val_dataloader()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "print(f\"Classes: {data_module.class_to_idx}\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Initialize Model & Training Components\n",
    "model = build_model(CONFIG[\"training\"], num_classes=len(CONFIG[\"dataset\"][\"classes\"]))\n",
    "loss_fn = build_loss(CONFIG[\"training\"])\n",
    "metrics = build_metrics(CONFIG[\"evaluation\"], num_classes=len(CONFIG[\"dataset\"][\"classes\"]), device=DEVICE)\n",
    "optimizer = build_optimizer(model, CONFIG[\"training\"])\n",
    "scheduler = build_scheduler(optimizer, CONFIG[\"training\"], epochs=CONFIG[\"training\"][\"epochs\"])\n",
    "\n",
    "# TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {CONFIG['paths']['logs_dir']}\n",
    "writer = SummaryWriter(log_dir=CONFIG[\"paths\"][\"logs_dir\"])\n",
    "\n",
    "# Start Training\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    device=DEVICE,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    metric_collection=metrics,\n",
    "    scheduler=scheduler,\n",
    "    epochs=CONFIG[\"training\"][\"epochs\"],\n",
    "    checkpoint_dir=CONFIG[\"paths\"][\"models_dir\"],\n",
    "    writer=writer\n",
    ")\n",
    "\n",
    "trainer.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff7ae4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5728,
     "status": "ok",
     "timestamp": 1763889041010,
     "user": {
      "displayName": "Kai Liang Ang (Kai)",
      "userId": "17787199631730325853"
     },
     "user_tz": -480
    },
    "id": "e3ff7ae4",
    "outputId": "9f6512a8-d22a-4ccd-fca5-cf10f7cafe48"
   },
   "outputs": [],
   "source": [
    "# @title 10. Run Testing\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the best model\n",
    "# checkpoint = torch.load(Path(CONFIG[\"paths\"][\"models_dir\"]) / \"best_model.pth\", map_location=torch.device('cpu')) #cpu usage comment out if using gpu\n",
    "checkpoint = torch.load(Path(CONFIG[\"paths\"][\"models_dir\"]) / \"best_model.pth\")#gpu usage comment out if using cpu\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CiEfAvqAxQFb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "2f6d081ac4c3455898cf0788e386d156",
      "7c214a40288441c4a8ec4e9c79f788fa",
      "41ae063b45d94e588c71dd222461c64e",
      "70e30fd4ec27420d91d2ef4ef60ab87e",
      "5937a3200ae34af38a0932371b307fb3",
      "1b6b2ee5af97485b87bd123737784c19",
      "93472b5b30b34f679b8812f3b7c4bfef",
      "024a572c32c74408b53189192d29b65a",
      "2aa12d9149e346f1998c71b8e49a9bf2",
      "303f8a96e0604ab291a1f82ab7392713",
      "d440559d913c49329c58b16ebfe6b6cc"
     ]
    },
    "id": "CiEfAvqAxQFb",
    "outputId": "232749e2-c367-42a9-bd53-366c8b5cc781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test started (1160 images) for evaluation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6d081ac4c3455898cf0788e386d156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = DEVICE\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "class_names = CONFIG[\"dataset\"][\"classes\"]\n",
    "print(f\"Test started ({len(test_loader.dataset)} images) for evaluation\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Evaluation Report(Best Model)\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names, digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "heatmap = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            annot_kws={\"size\": 14})\n",
    "\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.title('Confusion Matrix - Test Set', fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "accuracy = np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "print(f\"\\n✅ Test Accuracy: {accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "024a572c32c74408b53189192d29b65a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b6b2ee5af97485b87bd123737784c19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29950943cb8e471d93be9c748e7b55af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2aa12d9149e346f1998c71b8e49a9bf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2b166c86ef064bfcb408b895de1a3a14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f30910635914907b7b1064da803aca9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f6d081ac4c3455898cf0788e386d156": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c214a40288441c4a8ec4e9c79f788fa",
       "IPY_MODEL_41ae063b45d94e588c71dd222461c64e",
       "IPY_MODEL_70e30fd4ec27420d91d2ef4ef60ab87e"
      ],
      "layout": "IPY_MODEL_5937a3200ae34af38a0932371b307fb3"
     }
    },
    "303f8a96e0604ab291a1f82ab7392713": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "314f78d6193d4396a277bd603346f333": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41ae063b45d94e588c71dd222461c64e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_024a572c32c74408b53189192d29b65a",
      "max": 73,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2aa12d9149e346f1998c71b8e49a9bf2",
      "value": 0
     }
    },
    "498a9ef0681f41f1a83d995a5eae9915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5937a3200ae34af38a0932371b307fb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fa333c0b00746d8acf4ece60ac93ffa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "70e30fd4ec27420d91d2ef4ef60ab87e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_303f8a96e0604ab291a1f82ab7392713",
      "placeholder": "​",
      "style": "IPY_MODEL_d440559d913c49329c58b16ebfe6b6cc",
      "value": " 0/73 [00:00&lt;?, ?it/s]"
     }
    },
    "7c214a40288441c4a8ec4e9c79f788fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b6b2ee5af97485b87bd123737784c19",
      "placeholder": "​",
      "style": "IPY_MODEL_93472b5b30b34f679b8812f3b7c4bfef",
      "value": "Testing:   0%"
     }
    },
    "8f11dffc8d2b4b8e9fe06a047eac1c2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9bb94f35443c4b47ab1196a71a3842d7",
       "IPY_MODEL_f48d2ef3f8f143d48e149a289adc77b1",
       "IPY_MODEL_c03bf6dcc5a04fea8fb069011a6404aa"
      ],
      "layout": "IPY_MODEL_2f30910635914907b7b1064da803aca9"
     }
    },
    "8ff0c74af1454fd4bbbbd8cf8b0c1202": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93472b5b30b34f679b8812f3b7c4bfef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9bb94f35443c4b47ab1196a71a3842d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b166c86ef064bfcb408b895de1a3a14",
      "placeholder": "​",
      "style": "IPY_MODEL_498a9ef0681f41f1a83d995a5eae9915",
      "value": "model.safetensors: 100%"
     }
    },
    "c03bf6dcc5a04fea8fb069011a6404aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_314f78d6193d4396a277bd603346f333",
      "placeholder": "​",
      "style": "IPY_MODEL_29950943cb8e471d93be9c748e7b55af",
      "value": " 86.5M/86.5M [00:02&lt;00:00, 101MB/s]"
     }
    },
    "d440559d913c49329c58b16ebfe6b6cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f48d2ef3f8f143d48e149a289adc77b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ff0c74af1454fd4bbbbd8cf8b0c1202",
      "max": 86523256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5fa333c0b00746d8acf4ece60ac93ffa",
      "value": 86523256
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
